ctransformers==0.2.5 # To load the quantized model as we running the model on CPU. For langchain
sentence-transformer===2.2.2
pinecone-client
langchain==0.0.225
flask